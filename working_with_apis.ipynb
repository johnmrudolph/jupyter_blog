{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://raw.githubusercontent.com/johnmrudolph/jupyter_blog/master/headers/eia_api_header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#003f5b\">My setup & workflow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first post so before I dive into the content I thought it would be a good idea to give a short description of my setup and workflow. I do most of my work in linux (Ubuntu 16.04) and run Python 3.5. Most of my development is done via text editor (Sublime), IPython and command line. If I need to share or demo code then I use Jupyter but otherwise find it a bit clunky for development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#003f5b\">What's an API?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIs are important because they allow for ease of communication between applications. A good API can make life easier because the API has built in methods to do \"stuff\" which otherwise might require some tricky programming. For data science types, interacting with an API is a much easier way to dynamcally grab data from an online source than trying to scrub HTML or download some kind of static file. Each API will have its own nuances but generally you request information from an API by passing in parameters via a URL - basically a query string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#003f5b\">Creating a class to interact with an API</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most public APIs limit the size and number of request that you can make. There are tools that can help ensure that you are a respectful API user. The request-cache package is great for limiting unnecsarry API calls: https://pypi.python.org/pypi/requests-cache. You can also mock up API requests and responses which is helpful during development and unit testing: https://realpython.com/blog/python/testing-third-party-apis-with-mocks/.\n",
    "\n",
    "Before making a request you usually need an API key. Here is a link to the EIA Open Data page where you can obtain an EIA API key: http://www.eia.gov/opendata/register.cfm. We are going to use the requests package to call the EIA API and handle the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably take a look at the EIA API documentation: http://www.eia.gov/opendata/commands.cfm so that we know what a valid call should look like. Here is our example: http://api.eia.gov/series/?series_id=sssssss&api_key=YOUR_API_KEY_HERE[&num=][&out=xml|json]. So the parameters needed by the API follow the \"?\" in the URL string. Looks like we need a series_id and an API_KEY. The documentation also tells us that there are some optional parameters that we can pass in to filter the data that is returned to us in the response - we'll keep this in mind as we develop.\n",
    "\n",
    "Let's start by creating a class to handle the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetSeries(object):\n",
    "    '''\n",
    "    A class to call the EIA API and capture the response\n",
    "    '''\n",
    "    \n",
    "    # setting as class variable because the same url will be used for all calls\n",
    "    eia_url = 'http://api.eia.gov/series/'\n",
    "    \n",
    "    # (1)\n",
    "    # **kwargs will allow us to accept an unspecified number of keyword arguments\n",
    "    # this gives us flexibility to modify the class later on to handle optional parameters\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "        valid kwargs:\n",
    "        :param api_key: an valid API key provided by EIA\n",
    "        :param series: a valid EIA series ID\n",
    "        '''\n",
    "        self.kwargs = kwargs\n",
    "        self.parms = self.create_parms()\n",
    "        self.response = self.get_response()\n",
    "        \n",
    "    # (2)\n",
    "    def create_parms(self):\n",
    "        '''\n",
    "        Convert kwargs into a list to pass into api call\n",
    "        '''\n",
    "        try:\n",
    "            kwargs_list = [['api_key', self.kwargs['api_key']]]\n",
    "            kwargs_list.append(['series_id', self.kwargs['series_id']])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return kwargs_list\n",
    "    \n",
    "    # (3)\n",
    "    def get_response(self):\n",
    "        '''\n",
    "         Calls the EIA API and returns response object\n",
    "        '''\n",
    "        api_parms = [tuple(parm) for parm in self.parms]\n",
    "        return requests.get(self.eia_url, params=api_parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I numbered the 3 main elements of the GetSeries class which are worth explaining:\n",
    "\n",
    "(1) I set up the init to accept keyword arguments to allow for flexibilty. We will only be making an API call using 2 parameters: 1. An api_key and 2. a series_id. When the class is instantiated 3 attributes are created:\n",
    "    1. kwargs: this is a dictionary of key word arguments that can be passed into the class\n",
    "    2. parms: converts the kwargs into a list to pass into the api call\n",
    "    3. response: a response object returned from the EIA API\n",
    "    \n",
    "(2) When we pass in kwargs we get a dicitionary of key value pairs based on whatever the user has supplied. This means that we have to check for and handle the keyword arguments. In this case we need an api_key and series_id which we can check for using a try and accept. If both arguements have been passed in then we will create a list of key, value pairs. If neither of these keyword arguments have been passed in then we will raise a key error.\n",
    "\n",
    "(3) The api_key and series_id list is packed into a tuple of tuples andf then loaded into a URL using the request package. Note the the request package requires a tuple format of the paramters. The URL is interpreted by the EIA API and the relevent information is returned back as a response object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#003f5b\">What does the API response look like?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api_key and series_id are required inputs so these need to be defined before the GetSeries class can be instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in production you would want to keep the API key somewhere secret\n",
    "api_key = 'YOUR_API_KEY'\n",
    "\n",
    "# a list of valid EIA series can be found here: http://www.eia.gov/opendata/qb.cfm\n",
    "# I'll use \"Natural gas lower 48 weekly\"\n",
    "series_id = 'NG.NW2_EPG0_SWO_R48_BCF.W'\n",
    "\n",
    "# create a new GetSeries object based on the paramters defined above\n",
    "ng_stor = GetSeries(api_key=api_key, series_id=series_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we created a new instance of the GetSeries class called ng_stor. Lets start by taking a look at some of the information that we can get from the response attribute of the GerSeries class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API status code is <Response [200]>\n",
      "The API header is {'Access-Control-Allow-Origin': '*', 'Pragma': 'no-cache', 'Content-Encoding': 'gzip', 'Content-Type': 'application/json', 'Content-Length': '2264', 'Date': 'Fri, 30 Sep 2016 03:44:11 GMT', 'Content-Language': 'en', 'Server': 'Apache', 'Vary': 'Accept-Encoding', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Expires': 'Fri, 30 Sep 2016 03:44:11 GMT', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "# if we sent a valid request to the API then we should get a Reponse [200] status code\n",
    "print('The API status code is {}'.format(ng_stor.response))\n",
    "# this is the URL that we sent to the api - note I didn't show in the output below bc it has my API key embedded!\n",
    "print('The URL sent to the API is {}'.format(ng_stor.response.url))\n",
    "# this is some additional information about the response that the API sent to us\n",
    "print('The API header is {}'.format(ng_stor.response.headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The headers attribute of the response object gives us some helpful information about the API server and the content that was sent. The 'Content-Type\" is json so the Requests library can convert the response to a json object directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new variable to make it easier to work with the json\n",
    "ng_stor_json = ng_stor.response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#003f5b\">What can we do with the JSON?</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the entire json object is a bit messy so lets examine the json by using its keys since at this point it is really a dictionary as far as python is concerned. The API documentation: http://www.eia.gov/opendata/commands.cfm provides some detail about the json structure (it looks like a nested python dicitonary). The first level of the json has 2 keys: [request] and [series] and the data that we want is nested somewhere under [series]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of all the items avaialble to us from json:\n",
      "request:\n",
      "\tcommand\n",
      "\tseries_id\n",
      "series:\n",
      "\tstart\n",
      "\tunits\n",
      "\tf\n",
      "\tupdated\n",
      "\tname\n",
      "\tdescription\n",
      "\tcopyright\n",
      "\tend\n",
      "\tsource\n",
      "\tseries_id\n",
      "\tunitsshort\n",
      "\tdata\n"
     ]
    }
   ],
   "source": [
    "# create variables for the request and the series\n",
    "request = ng_stor_json['request']\n",
    "series = ng_stor_json['series']\n",
    "\n",
    "print('Here is a list of all the items avaialble to us from json:')\n",
    "\n",
    "# print each key in the request\n",
    "print('request:')\n",
    "for key in request.keys():\n",
    "    print('\\t{}'.format(key))\n",
    "    \n",
    "# print each key in series - note that the level below series is a dictinary nested in a list - series[0]\n",
    "print('series:')\n",
    "for key in series[0].keys():\n",
    "    print('\\t{}'.format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data attribute that is nested under series is what we are after so lets extract it and convert to a pandas dataframe and create a datetime index to make it a proper timeseries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 style=\"color:#003f5b\">Parse the JSON to a Pandas dataframe</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to import pandas - ideally this import would happen at the start of the script\n",
    "# and datetime to convert a string to a timestamp\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think either a function or a class could be used here to parse the json into a dataframe. I'm going to use a class because I used a class to interact with the API so I might as well keep the object oriented thing going. I'm also going to build in some flexibility to handle different datetime frequencies so that this class can be used to handle all EIA time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CreateDataFrame(object):\n",
    "    '''Creates the dataframe for Energy API call'''\n",
    "    \n",
    "    # (1)\n",
    "    def __init__(self, json):\n",
    "        \"\"\":param json: eia json\"\"\"\n",
    "        self.json = json\n",
    "        self.series = self.json['series']\n",
    "        self.data = self.series[0]['data']\n",
    "        self.df = self.create_dataframe()\n",
    "    \n",
    "    # (2)\n",
    "    def create_dataframe(self):\n",
    "        \"\"\"Function to create dataframe from json['series'] \"\"\"\n",
    "        values = [x[1] for x in self.data]\n",
    "        dates = self.get_dates()\n",
    "        return pd.DataFrame(values, index=dates, columns=['values'])\n",
    "    \n",
    "    # (3)\n",
    "    def get_dates(self):\n",
    "        \"\"\"Parses text dates to datetime index\"\"\"\n",
    "        freq = {'A': '%Y', 'M': '%Y%m', 'W': '%Y%m%d',\n",
    "                'D': '%Y%m%d', 'H': '%Y%m%d %H'}\n",
    "        date_list = []\n",
    "        for x in self.data:\n",
    "            # need to add this ugly bit to remove hourly time format from EIA\n",
    "            time = x[0].replace('T', ' ')\n",
    "            time = time.replace('Z', '')\n",
    "            time = datetime.strptime(time, freq[self.series[0]['f']])\n",
    "            date_list.append(time.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) When the class is instantiated 4 attributes are created:\n",
    "    1. json: the json that was passed in from the EIA API\n",
    "    2. series: the series key of the json object\n",
    "    3. data: the data key that is embedded in series\n",
    "    4. df: a pandas dataframe\n",
    "    \n",
    "(2) A class method used to take the data key values from json and convert it to a pandas dataframe. The data key holds a list of lists that contains a date and value. This code extracts the value from the list and calls another method to extract the dates and convert to datetime. The dataframe is created by using the converted datetime to assign an index.\n",
    "\n",
    "(3) A class method used to convert a string representation of dates to a datetime object. I built this to handle the different frequencies that could potentially be passes in since EIA data can be annual, monthly, weekly, daily or hourly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the dataframe to check if the the CreateDataFrame class is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     values\n",
      "2016-09-23 00:00:00    3600\n",
      "2016-09-16 00:00:00    3551\n",
      "2016-09-09 00:00:00    3499\n",
      "2016-09-02 00:00:00    3437\n",
      "2016-08-26 00:00:00    3401\n",
      "2016-08-19 00:00:00    3350\n",
      "2016-08-12 00:00:00    3339\n",
      "2016-08-05 00:00:00    3317\n",
      "2016-07-29 00:00:00    3288\n",
      "2016-07-22 00:00:00    3294\n",
      "2016-07-15 00:00:00    3277\n",
      "2016-07-08 00:00:00    3243\n",
      "2016-07-01 00:00:00    3179\n",
      "2016-06-24 00:00:00    3140\n",
      "2016-06-17 00:00:00    3103\n",
      "2016-06-10 00:00:00    3041\n",
      "2016-06-03 00:00:00    2972\n",
      "2016-05-27 00:00:00    2907\n",
      "2016-05-20 00:00:00    2825\n",
      "2016-05-13 00:00:00    2754\n"
     ]
    }
   ],
   "source": [
    "# here we create instantiate the CreateDataFrame class and assign the df attribute\n",
    "ng_stor_df = CreateDataFrame(ng_stor_json).df\n",
    "# print out the first 20 obs\n",
    "print(ng_stor_df.head(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The dataframe looks good - it gives us a nice clean time series that is ready to be modelled. I'll be using the EIA API, GetSeries and CreateDataframe classes in my next post where I play around with outlier detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
