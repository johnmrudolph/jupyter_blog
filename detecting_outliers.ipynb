{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/johnr_000/jupyter_blog/jupyter_blog/scripts')\n",
    "import eia_model as em\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variables to specify date range and frequency\n",
    "api_key = em.eia_api\n",
    "start = '2015-12-01 01:00:00'\n",
    "end = '2016-01-31 23:00:00'\n",
    "freq = 'H'\n",
    "# create list of series used for dictionary keys\n",
    "keys = ['EBA.BPAT-ALL.D.H', 'EBA.PACE-ALL.D.H', 'EBA.PACW-ALL.D.H', \n",
    "        'EBA.PGE-ALL.D.H', 'EBA.PSEI-ALL.D.H', 'EBA.SCL-ALL.D.H']\n",
    "# create dict of GetSeriesRange objects from series list\n",
    "series_dict = {key: em.GetSeries(api_key=api_key, series_id=key, \n",
    "                                   start=start, end=end, freq=freq) for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demand for PacifiCorp West (PACW), Hourly: EBA.PACW-ALL.D.H\n",
      "Demand for Seattle City Light (SCL), Hourly: EBA.SCL-ALL.D.H\n",
      "Demand for Portland General Electric Company (PGE), Hourly: EBA.PGE-ALL.D.H\n",
      "Demand for Puget Sound Energy, Inc. (PSEI), Hourly: EBA.PSEI-ALL.D.H\n",
      "Demand for Bonneville Power Administration (BPAT), Hourly: EBA.BPAT-ALL.D.H\n",
      "Demand for PacifiCorp East (PACE), Hourly: EBA.PACE-ALL.D.H\n"
     ]
    }
   ],
   "source": [
    "# loop over dictionary and print out full name of each series\n",
    "for key in series_dict:\n",
    "    print('{}: {}'.format(series_dict[key].data.series[0]['name'],key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all the dataframes have the same date range so we can concatenate in a loop\n",
    "concat_df = pd.concat([series_dict[key].data.df for key in series_dict], axis=1)\n",
    "# and output as a pickle file - I'm doing this to avoid calling the EIA API as I develop\n",
    "concat_df.to_pickle('data/nw_load_df.pkl')\n",
    "# concat_df = pd.read_pickle('data/new_load_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnr_000/venv_python3/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EBA.PACW-ALL.D.H</th>\n",
       "      <th>EBA.SCL-ALL.D.H</th>\n",
       "      <th>EBA.PGE-ALL.D.H</th>\n",
       "      <th>EBA.PSEI-ALL.D.H</th>\n",
       "      <th>EBA.BPAT-ALL.D.H</th>\n",
       "      <th>EBA.PACE-ALL.D.H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.487000e+03</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>1487.000000</td>\n",
       "      <td>1.487000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.451198e+03</td>\n",
       "      <td>1282.258911</td>\n",
       "      <td>2579.921991</td>\n",
       "      <td>3946.066127</td>\n",
       "      <td>7059.477471</td>\n",
       "      <td>-2.470617e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.558528e+04</td>\n",
       "      <td>177.394473</td>\n",
       "      <td>385.764476</td>\n",
       "      <td>554.268601</td>\n",
       "      <td>833.190306</td>\n",
       "      <td>8.950455e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.785000e+03</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>-3.199017e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.393500e+03</td>\n",
       "      <td>1128.500000</td>\n",
       "      <td>2272.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6451.500000</td>\n",
       "      <td>5.169000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.709000e+03</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>2646.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7109.000000</td>\n",
       "      <td>5.508000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.941500e+03</td>\n",
       "      <td>1416.000000</td>\n",
       "      <td>2872.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7637.500000</td>\n",
       "      <td>5.822500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.530003e+06</td>\n",
       "      <td>1654.000000</td>\n",
       "      <td>3472.000000</td>\n",
       "      <td>5088.000000</td>\n",
       "      <td>9365.000000</td>\n",
       "      <td>5.966800e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EBA.PACW-ALL.D.H  EBA.SCL-ALL.D.H  EBA.PGE-ALL.D.H  EBA.PSEI-ALL.D.H  \\\n",
       "count      1.487000e+03      1487.000000      1487.000000       1482.000000   \n",
       "mean       4.451198e+03      1282.258911      2579.921991       3946.066127   \n",
       "std        6.558528e+04       177.394473       385.764476        554.268601   \n",
       "min       -6.785000e+03       868.000000      1730.000000       2292.000000   \n",
       "25%        2.393500e+03      1128.500000      2272.000000               NaN   \n",
       "50%        2.709000e+03      1324.000000      2646.000000               NaN   \n",
       "75%        2.941500e+03      1416.000000      2872.500000               NaN   \n",
       "max        2.530003e+06      1654.000000      3472.000000       5088.000000   \n",
       "\n",
       "       EBA.BPAT-ALL.D.H  EBA.PACE-ALL.D.H  \n",
       "count       1487.000000      1.487000e+03  \n",
       "mean        7059.477471     -2.470617e+04  \n",
       "std          833.190306      8.950455e+05  \n",
       "min         5006.000000     -3.199017e+07  \n",
       "25%         6451.500000      5.169000e+03  \n",
       "50%         7109.000000      5.508000e+03  \n",
       "75%         7637.500000      5.822500e+03  \n",
       "max         9365.000000      5.966800e+04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataframe: 1189 and testing dataframe 298\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(concat_df, test_size = 0.2)\n",
    "print('Length of training dataframe: {} and testing dataframe {}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnr_000/venv_python3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1189]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-379599018253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EBA.SCL-ALL.D.H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EBA.SCL-ALL.D.H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EBA.SCL-ALL.D.H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnr_000/venv_python3/lib/python3.5/site-packages/sklearn/ensemble/iforest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    196\u001b[0m         super(IsolationForest, self)._fit(X, y, max_samples,\n\u001b[1;32m    197\u001b[0m                                           \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                                           sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         self.threshold_ = -sp.stats.scoreatpercentile(\n",
      "\u001b[0;32m/home/johnr_000/venv_python3/lib/python3.5/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Convert data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Remap output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnr_000/venv_python3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnr_000/venv_python3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 1189]"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(train['EBA.SCL-ALL.D.H'])\n",
    "y_pred_train = clf.predict(train['EBA.SCL-ALL.D.H'])\n",
    "y_pred_test = clf.predict(test['EBA.SCL-ALL.D.H'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015-12-27 20:00:00    1367\n",
       "2015-12-21 19:00:00    1524\n",
       "2015-12-07 19:00:00    1417\n",
       "2015-12-06 13:00:00     966\n",
       "2016-01-21 17:00:00    1410\n",
       "2016-01-26 02:00:00    1477\n",
       "2015-12-09 13:00:00     920\n",
       "2015-12-30 14:00:00    1264\n",
       "2015-12-08 01:00:00    1435\n",
       "2016-01-06 22:00:00    1316\n",
       "2015-12-06 12:00:00     962\n",
       "2016-01-02 03:00:00    1450\n",
       "2015-12-20 14:00:00    1056\n",
       "2015-12-23 00:00:00    1445\n",
       "2015-12-16 01:00:00    1535\n",
       "2015-12-29 04:00:00    1456\n",
       "2016-01-24 09:00:00    1039\n",
       "2016-01-18 10:00:00     996\n",
       "2015-12-10 04:00:00    1356\n",
       "2016-01-13 07:00:00    1217\n",
       "2015-12-01 12:00:00    1067\n",
       "2015-12-04 19:00:00    1363\n",
       "2015-12-28 12:00:00    1052\n",
       "2016-01-25 02:00:00    1343\n",
       "2016-01-18 17:00:00    1380\n",
       "2016-01-09 03:00:00    1503\n",
       "2015-12-24 06:00:00    1357\n",
       "2016-01-28 07:00:00    1112\n",
       "2016-01-09 08:00:00    1213\n",
       "2016-01-06 20:00:00    1376\n",
       "                       ... \n",
       "2015-12-22 19:00:00    1517\n",
       "2016-01-03 12:00:00    1090\n",
       "2016-01-29 03:00:00    1338\n",
       "2016-01-01 14:00:00    1212\n",
       "2015-12-21 07:00:00    1276\n",
       "2015-12-20 15:00:00    1120\n",
       "2015-12-24 16:00:00    1358\n",
       "2016-01-07 16:00:00    1535\n",
       "2016-01-23 10:00:00     985\n",
       "2015-12-27 07:00:00    1226\n",
       "2015-12-06 16:00:00    1118\n",
       "2015-12-26 02:00:00    1311\n",
       "2016-01-04 16:00:00    1586\n",
       "2016-01-22 22:00:00    1283\n",
       "2015-12-16 15:00:00    1369\n",
       "2016-01-18 11:00:00     976\n",
       "2016-01-22 06:00:00    1260\n",
       "2016-01-24 07:00:00    1182\n",
       "2015-12-14 06:00:00    1332\n",
       "2016-01-15 13:00:00    1094\n",
       "2016-01-13 08:00:00    1089\n",
       "2015-12-01 19:00:00    1436\n",
       "2015-12-20 08:00:00    1164\n",
       "2015-12-30 18:00:00    1543\n",
       "2016-01-03 05:00:00    1426\n",
       "2015-12-03 19:00:00    1352\n",
       "2016-01-30 15:00:00    1117\n",
       "2015-12-30 01:00:00    1448\n",
       "2015-12-03 15:00:00    1271\n",
       "2015-12-05 21:00:00    1357\n",
       "Name: EBA.SCL-ALL.D.H, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['EBA.SCL-ALL.D.H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
